{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Image Generation using Fine-Tuning Stable Diffusion Model and Metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vr5EKHnLTvus",
    "outputId": "b0fb12d2-f025-4170-8da1-138b918e7384",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-3.5.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (10.0.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (2.31.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.2)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Downloading pyarrow-20.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting requests\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tqdm>=4.66.3 (from datasets)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2023.12.2)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Downloading aiohttp-3.11.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting huggingface-hub>=0.24.0 (from datasets)\n",
      "  Downloading huggingface_hub-0.30.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3.post1)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests) (2023.11.17)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp->datasets)\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Downloading frozenlist-1.6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Downloading multidict-6.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->datasets)\n",
      "  Downloading propcache-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets)\n",
      "  Downloading yarl-1.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (72 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.4/72.4 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.24.0->datasets) (4.7.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading datasets-3.5.1-py3-none-any.whl (491 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.4/491.4 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.11.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m481.4/481.4 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-20.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (42.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.8/347.8 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Downloading frozenlist-1.6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (287 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.3/287.3 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (219 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m219.8/219.8 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading propcache-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (206 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m206.6/206.6 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading yarl-1.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (333 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m333.9/333.9 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xxhash, tzdata, tqdm, requests, pyarrow, propcache, multidict, frozenlist, dill, async-timeout, aiohappyeyeballs, yarl, pandas, multiprocess, huggingface-hub, aiosignal, aiohttp, datasets\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.65.0\n",
      "    Uninstalling tqdm-4.65.0:\n",
      "      Successfully uninstalled tqdm-4.65.0\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.31.0\n",
      "    Uninstalling requests-2.31.0:\n",
      "      Successfully uninstalled requests-2.31.0\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.11.18 aiosignal-1.3.2 async-timeout-5.0.1 datasets-3.5.1 dill-0.3.8 frozenlist-1.6.0 huggingface-hub-0.30.2 multidict-6.4.3 multiprocess-0.70.16 pandas-2.2.3 propcache-0.3.1 pyarrow-20.0.0 requests-2.32.3 tqdm-4.67.1 tzdata-2025.2 xxhash-3.5.0 yarl-1.20.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install datasets pandas pillow requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "8VWxL7jH2Arf",
    "outputId": "6039b1e5-3391-45c1-c721-b930269a4aa6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting accelerate==1.0.1\n",
      "  Downloading accelerate-1.0.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting diffusers==0.30.3\n",
      "  Downloading diffusers-0.30.3-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting numpy==2.1.2\n",
      "  Downloading numpy-2.1.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pillow==11.0.0\n",
      "  Downloading pillow-11.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
      "Collecting torch==2.4.1\n",
      "  Downloading torch-2.4.1-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "Collecting torchvision==0.19.1\n",
      "  Downloading torchvision-0.19.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.0 kB)\n",
      "Collecting tqdm==4.66.5\n",
      "  Downloading tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting transformers==4.45.2\n",
      "  Downloading transformers-4.45.2-py3-none-any.whl.metadata (44 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==1.0.1) (23.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate==1.0.1) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate==1.0.1) (6.0.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==1.0.1) (0.30.2)\n",
      "Collecting safetensors>=0.4.3 (from accelerate==1.0.1)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting importlib-metadata (from diffusers==0.30.3)\n",
      "  Downloading importlib_metadata-8.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from diffusers==0.30.3) (3.13.1)\n",
      "Collecting regex!=2019.12.17 (from diffusers==0.30.3)\n",
      "  Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from diffusers==0.30.3) (2.32.3)\n",
      "Collecting typing-extensions>=4.8.0 (from torch==2.4.1)\n",
      "  Downloading typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.4.1) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.4.1) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.4.1) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch==2.4.1) (2023.12.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.4.1)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.4.1)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.4.1)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.4.1)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.4.1)\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.4.1)\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.4.1)\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.4.1)\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.4.1)\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.4.1)\n",
      "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.4.1)\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==3.0.0 (from torch==2.4.1)\n",
      "  Downloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers==4.45.2)\n",
      "  Downloading tokenizers-0.20.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.1)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting zipp>=3.20 (from importlib-metadata->diffusers==0.30.3)\n",
      "  Downloading zipp-3.21.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.4.1) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->diffusers==0.30.3) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->diffusers==0.30.3) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->diffusers==0.30.3) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->diffusers==0.30.3) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.4.1) (1.3.0)\n",
      "Downloading accelerate-1.0.1-py3-none-any.whl (330 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.9/330.9 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading diffusers-0.30.3-py3-none-any.whl (2.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.1.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pillow-11.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.4.1-cp310-cp310-manylinux1_x86_64.whl (797.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.1/797.1 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.19.1-cp310-cp310-manylinux1_x86_64.whl (7.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.45.2-py3-none-any.whl (9.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.7/781.7 kB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.20.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading importlib_metadata-8.7.0-py3-none-any.whl (27 kB)\n",
      "Downloading zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
      "Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: zipp, typing-extensions, triton, tqdm, safetensors, regex, pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, nvidia-cusparse-cu12, nvidia-cudnn-cu12, importlib-metadata, tokenizers, nvidia-cusolver-cu12, diffusers, transformers, torch, torchvision, accelerate\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.7.1\n",
      "    Uninstalling typing_extensions-4.7.1:\n",
      "      Successfully uninstalled typing_extensions-4.7.1\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 2.1.0\n",
      "    Uninstalling triton-2.1.0:\n",
      "      Successfully uninstalled triton-2.1.0\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.67.1\n",
      "    Uninstalling tqdm-4.67.1:\n",
      "      Successfully uninstalled tqdm-4.67.1\n",
      "  Attempting uninstall: pillow\n",
      "    Found existing installation: Pillow 10.0.1\n",
      "    Uninstalling Pillow-10.0.1:\n",
      "      Successfully uninstalled Pillow-10.0.1\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.2\n",
      "    Uninstalling numpy-1.26.2:\n",
      "      Successfully uninstalled numpy-1.26.2\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.1.2\n",
      "    Uninstalling torch-2.1.2:\n",
      "      Successfully uninstalled torch-2.1.2\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.16.2\n",
      "    Uninstalling torchvision-0.16.2:\n",
      "      Successfully uninstalled torchvision-0.16.2\n",
      "Successfully installed accelerate-1.0.1 diffusers-0.30.3 importlib-metadata-8.7.0 numpy-2.1.2 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvtx-cu12-12.1.105 pillow-11.0.0 regex-2024.11.6 safetensors-0.5.3 tokenizers-0.20.3 torch-2.4.1 torchvision-0.19.1 tqdm-4.66.5 transformers-4.45.2 triton-3.0.0 typing-extensions-4.13.2 zipp-3.21.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install \\\n",
    "    accelerate==1.0.1 \\\n",
    "    diffusers==0.30.3 \\\n",
    "    numpy==2.1.2 \\\n",
    "    pillow==11.0.0 \\\n",
    "    torch==2.4.1 \\\n",
    "    torchvision==0.19.1 \\\n",
    "    tqdm==4.66.5 \\\n",
    "    transformers==4.45.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9gtYEZ_0zgAH",
    "outputId": "afc6339d-0254-4e60-8f52-010597a9c14a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-8.1.6-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (8.15.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (5.7.1)\n",
      "Collecting widgetsnbextension~=4.0.14 (from ipywidgets)\n",
      "  Downloading widgetsnbextension-4.0.14-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab_widgets~=3.0.14 (from ipywidgets)\n",
      "  Downloading jupyterlab_widgets-3.0.14-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.36)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.15.1)\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (1.0.4)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: executing in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: asttokens in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from asttokens->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "Downloading ipywidgets-8.1.6-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jupyterlab_widgets-3.0.14-py3-none-any.whl (213 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.0/214.0 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading widgetsnbextension-4.0.14-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: widgetsnbextension, jupyterlab_widgets, ipywidgets\n",
      "Successfully installed ipywidgets-8.1.6 jupyterlab_widgets-3.0.14 widgetsnbextension-4.0.14\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3vMDkodafcEE",
    "outputId": "53b44545-2be7-4bab-960e-947bd9446aa3",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: tqdm 4.66.5\n",
      "Uninstalling tqdm-4.66.5:\n",
      "  Successfully uninstalled tqdm-4.66.5\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting tqdm\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.67.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y tqdm\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DTsxYuuBfcEF",
    "outputId": "bbc46173-139f-427a-e2bb-8086a4978c8f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting peft\n",
      "  Downloading peft-0.15.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (23.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.4.1)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.45.2)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.67.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (1.0.1)\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.5.3)\n",
      "Requirement already satisfied: huggingface_hub>=0.25.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.30.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub>=0.25.0->peft) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub>=0.25.0->peft) (2023.12.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface_hub>=0.25.0->peft) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub>=0.25.0->peft) (4.13.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft) (12.8.93)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.20.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub>=0.25.0->peft) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub>=0.25.0->peft) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub>=0.25.0->peft) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub>=0.25.0->peft) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
      "Downloading peft-0.15.2-py3-none-any.whl (411 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.1/411.1 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: peft\n",
      "Successfully installed peft-0.15.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RCluf13zrrF1",
    "outputId": "61c9296d-9f8b-465e-c787-411a20bace77",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchmetrics[image]\n",
      "  Downloading torchmetrics-1.7.1-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: numpy>1.20.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics[image]) (2.1.2)\n",
      "Requirement already satisfied: packaging>17.1 in /opt/conda/lib/python3.10/site-packages (from torchmetrics[image]) (23.1)\n",
      "Requirement already satisfied: torch>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics[image]) (2.4.1)\n",
      "Collecting lightning-utilities>=0.8.0 (from torchmetrics[image])\n",
      "  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting torch-fidelity<=0.4.0 (from torchmetrics[image])\n",
      "  Downloading torch_fidelity-0.3.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: torchvision>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from torchmetrics[image]) (0.19.1)\n",
      "Collecting scipy>1.0.0 (from torchmetrics[image])\n",
      "  Downloading scipy-1.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->torchmetrics[image]) (68.2.2)\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->torchmetrics[image]) (4.13.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->torchmetrics[image]) (3.13.1)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->torchmetrics[image]) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->torchmetrics[image]) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->torchmetrics[image]) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->torchmetrics[image]) (2023.12.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->torchmetrics[image]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->torchmetrics[image]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->torchmetrics[image]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->torchmetrics[image]) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->torchmetrics[image]) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->torchmetrics[image]) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->torchmetrics[image]) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->torchmetrics[image]) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->torchmetrics[image]) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->torchmetrics[image]) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->torchmetrics[image]) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->torchmetrics[image]) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.0->torchmetrics[image]) (12.8.93)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from torch-fidelity<=0.4.0->torchmetrics[image]) (11.0.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from torch-fidelity<=0.4.0->torchmetrics[image]) (4.67.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=2.0.0->torchmetrics[image]) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=2.0.0->torchmetrics[image]) (1.3.0)\n",
      "Downloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
      "Downloading scipy-1.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.6/37.6 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torch_fidelity-0.3.0-py3-none-any.whl (37 kB)\n",
      "Downloading torchmetrics-1.7.1-py3-none-any.whl (961 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m961.5/961.5 kB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: scipy, lightning-utilities, torchmetrics, torch-fidelity\n",
      "Successfully installed lightning-utilities-0.14.3 scipy-1.15.2 torch-fidelity-0.3.0 torchmetrics-1.7.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchmetrics[image]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SJ0TtWaSzgAI"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A68UgBuQPf7e"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "root_dir = \"Lab2/\"\n",
    "\n",
    "\n",
    "DATASET_DIR = root_dir +\"dataset/\"\n",
    "CAPTIONS_FILE = DATASET_DIR + \"image_captions.csv\"\n",
    "\n",
    "FINETUNED_MODEL_DIR = root_dir + \"fine_tuned_models/\"\n",
    "\n",
    "RESULTS_DIR = root_dir + \"results/\"\n",
    "RESIZED_RESULTS_DIR = root_dir + \"resized_images/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define LoRA layer and helper functions to add LoRA layer to the base Stable Diffusion model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BeWtlvzXjbo3"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LoRALinear(nn.Module):\n",
    "    def __init__(self, linear, rank=4, alpha=1):\n",
    "        super().__init__()\n",
    "        self.linear = linear\n",
    "        self.lora = LoRALayer(linear.in_features, linear.out_features, rank, alpha)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x) + self.lora(x)\n",
    "\n",
    "class LoRALayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features, rank=4, alpha=1, dtype=torch.float32):\n",
    "        super().__init__()\n",
    "        self.lora_A = nn.Parameter(torch.zeros((rank, in_features), dtype=dtype))\n",
    "        self.lora_B = nn.Parameter(torch.zeros((out_features, rank), dtype=dtype))\n",
    "        self.scale = alpha / rank\n",
    "        nn.init.kaiming_uniform_(self.lora_A, a=math.sqrt(5))\n",
    "        nn.init.zeros_(self.lora_B)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return (x @ self.lora_A.T @ self.lora_B.T) * self.scale\n",
    "\n",
    "def add_lora_to_linear(linear, rank=4, alpha=1):\n",
    "    lora = LoRALayer(linear.in_features, linear.out_features, rank, alpha)\n",
    "    return lambda x: linear(x) + lora(x)\n",
    "\n",
    "def apply_lora_to_model(model, rank=4, alpha=1):\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.Linear):\n",
    "            parent_name = '.'.join(name.split('.')[:-1])\n",
    "            child_name = name.split('.')[-1]\n",
    "            parent = model.get_submodule(parent_name)\n",
    "            lora_layer = LoRALinear(module, rank, alpha)\n",
    "            lora_layer = lora_layer.to(module.weight.device, module.weight.dtype)\n",
    "            setattr(parent, child_name, lora_layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions to save/load weights of LoRA layer trained with base Stable Diffusion model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lcWlHHr9Oqip"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def save_lora_weights(model, path):\n",
    "    lora_state_dict = {}\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, LoRALayer):\n",
    "            lora_state_dict[f\"{name}.lora_A\"] = module.lora_A\n",
    "            lora_state_dict[f\"{name}.lora_B\"] = module.lora_B\n",
    "    torch.save(lora_state_dict, path)\n",
    "    print(f\"LoRA weights saved to {path}\")\n",
    "\n",
    "def load_lora_weights(model, path):\n",
    "    lora_state_dict = torch.load(path)\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, LoRALayer):\n",
    "            module.lora_A.data = lora_state_dict[f\"{name}.lora_A\"]\n",
    "            module.lora_B.data = lora_state_dict[f\"{name}.lora_B\"]\n",
    "    print(f\"LoRA weights loaded from {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the pretrained base Stable Diffusion model from hub, inject LoRA layer to the model pipeline and load weights for the LoRA layer from model file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 797,
     "referenced_widgets": [
      "cc867ee633cd4be38cf262c16d4a3c38",
      "395276ffd5fe4916a6b12402ea79c71f",
      "d9139379c94e4e2c8b2b6b55272445d3",
      "3a76d7bc202e493b8b67197bdfc0d54b",
      "f873f8ff70f542f185814d9c3437214a",
      "fd5d40b83ab8490bad566133441961d3",
      "17ff5489fcac4d20ab3f852cb47c8982",
      "db21767036194c6ebbec4e79a0ee6b2d",
      "812bb585cac8473b9b1d586541c0dd5b",
      "f0968418a6d84e06914fd7133e547e57",
      "9c2b63caeccf4599a4701efb306d96a7",
      "d684493f134d4641b326ebe0e43b2658",
      "fd7daadb5a2a425a883333a6029f53be",
      "358f960a20da47c7b8a7cfcc2da06984",
      "b1242a7036ad4e488b39d396705fb894",
      "a0c75185a16d40be863bb33e4d4fd5ef",
      "d7a4992ea0214bbd8670052b37c677de",
      "f3555c6beb7b48c3b438b346a6d26555",
      "bbe9953fb6b049da94a0a114c0d3dcba",
      "97222ae2ff3543519e5ca3049fc699a0",
      "7b62eb4763644812900cd507c7853fa2",
      "265924bf98f1416c82f2115b18e8cd3e",
      "76816c16527f445b81554f519070ed86",
      "4c7a0971d7f14cd0a617949f6328786d",
      "8555b333310c433a84ab21e68778a2d0",
      "4a4b06d9d32e4d00802e617e0fc260a1",
      "896c8f4eab2948e286121d38a98510e3",
      "106670ea4ae64a7b97fbee2b4ee62bc3",
      "6d5be8a0f99f4f36b562a713fd2fb585",
      "15d708ca7a644807afd40fa430fc3364",
      "8eb76eeb1517489aa4a065a0011092e6",
      "7ab2b5c308514d8dbdaca797e48fb8c1",
      "9242a6ee79634da6a36dab87d8ce9dd3",
      "a287d712edf44e2a9744987ce2a4dcf7",
      "99ed6968d24e459f8923c66f57b317c3",
      "664cec75e3d44fa8821076768ddbab7f",
      "5cd33735eee2415dae833ddd6c3d388e",
      "8b95e1ce34514f769c46fa53059ade14",
      "fb94dba638e043b49bde754246d43ef2",
      "f2409c548bf14996bd5581d67891a43e",
      "32d928328d1e448481273e93e82a11c7",
      "189ed2abd51e40fea4e278e05ac7eb42",
      "f06d32bbdabf4758a8e5c771f1cbe26e",
      "76484af11fb943689006069ad9e027e0",
      "0cb1429ce1744a72ba7b2ed33e85d3bf",
      "e25d5de6ad0d45bfbb20d39cc5f967d5",
      "bf21eab793ba462fb9d259ab2f04ab34",
      "58ce4d9391f44d9b9bd7e43d27b18bd1",
      "d2ce10c269c54c659d4fcb008776e7db",
      "749662978d61403f9763b2e018586394",
      "d1e6bbadbf4b4706ac212c51e3d6efab",
      "ad88063e968741c8b609f46c7d886b79",
      "ea87221316964de793a0518dfb0ddef5",
      "4c453db3093e404d9daa29f8d77d03d5",
      "07f6cdc2d6d548a89bd0c0803e94f899",
      "12dfb592aa8b4eefaedcaab2e664aed9",
      "adc81816bafa487999c73b43b5657345",
      "47a3b744f8084367b1d99829a4808bf4",
      "fd48955d212e46fdae2fb6e632e22d10",
      "c1c1d54c1e4d4c2e9cbbe9cf0fe670f3",
      "8b62273f3a81445a8ca86f39373f8ca8",
      "ff1e558c060b4ba38c5ba3afb2d4535c",
      "ebdbc2ee16fa4f56acfed0891a9cbcde",
      "916436edeb594eebbcac53c3adc3e6e0",
      "8d2a060d67f54853bf247b3908551349",
      "43929f2149244489a769435206816b8a",
      "840dff2a30b848c9a7989bcec1f7b370",
      "98f0664bb930458a83b65cd612bcf63f",
      "e584bf9309e14064acc87c5d89435f7d",
      "0872ec57d20a47449fe25d3072dfe864",
      "1fcc4a82e8af40a0942f1a93915ea8d2",
      "bd319ce82ef7416c80c8a1aa307235cf",
      "22a516cfa29549f389ecf8e624c87904",
      "c033734be0f14d9abbdb833805530950",
      "0ea51614ee6b4de684e30022591d8f8d",
      "98881e77c58b48ba9299342a997f2876",
      "4394742dc1f240ec80a18f87dad84c17",
      "c43aa7d6aeaf4dfc9f3283653a73826f",
      "1f5c89c63da7453b89f75e42307f1443",
      "b28210e77ca543488d3d500a0289e89e",
      "01b3940d9236490087a64816771be927",
      "488b39fc9599468f9d03e4f09c5621d8",
      "e4848a581c4848708fab441797a56704",
      "562103e7668f4e69a511bedc1bdbeed4",
      "ae034193f3634811852bab9078b42df6",
      "d5de84fd084b47b5a172fccb76ccff56",
      "3abb57c4880e481cbe3a312d75ab923e",
      "3cde48191ae64c5792cf608583f7e7d1",
      "377e1978594d4173a7a5d02a8818a153",
      "e00cc48a2bc14d388fc7142829e88c2e",
      "9822b658cade4048b11ad79dbb22ddea",
      "a1d001749d1c422f879228ebe07d3403",
      "6f5a4539a84246139c87953aca122b3d",
      "c1bdd593dcd7435b99ad02d8e06bffd8",
      "80f072f43ca541c7a503c66b921f5137",
      "f6c32a1bd9344af5ab0d5fcd7d663d53",
      "6d635657021c49e3b34fd1a71d498e08",
      "8bd2efb07efa48c78cb770408dd2ab7f",
      "bcf34c4e878843b29e00554a1bebaa01",
      "1a16b5bbaf21496f8a51998f83fd9149",
      "e0a8e6b6a45a4283a4dc645faa22f596",
      "0f397d8dfb2547a292bf2f27d404318c",
      "d5f98f91e8584b48ad37da033730544f",
      "2803e21363954c5c8b9370a5eb55f348",
      "daf25b8457014279b2fec068cac7edbb",
      "a2795a91fe1940c09b36344f1ed673c0",
      "c5b946ac421840a1bbc97be870610577",
      "cd7ee5de971e4baca828490d892998ec",
      "81d031dfd1c64aedbc670bc7a59e9ef2",
      "596a27fa78064658b662f308d1b71264",
      "723d9f3df53e4462ac451ef6873b9ac0",
      "2c987fa1abe947ea8db6798087b1e7f0",
      "9fda858f27ee4c0d8748aacd441a4446",
      "80713a5ddfe645ac8e1f2b7f1ba7a437",
      "99ccdacc4c04420d9b446b2ae3dd5734",
      "71dfcdb9bded431e996247e307bd5d2b",
      "37661477eaa24c348a5fb1277bb9a3a1",
      "73ea9aec0c6a4ed9b03de61dc479a7a6",
      "2402d7b6618d40499d6f5f5df28e5fe4",
      "1bbdccb631eb49c5b93d68d4972f5c52",
      "018566e129454e899a2dd799a60d7706",
      "086fb82f41f04d41ba357d3e6f733275",
      "a37549db978946cdbe0bf6cbc3c3e180",
      "83ab300eb7d8487883dfb1084b6a0fcd",
      "4e69ada3ebbc4964a7117ad48282f69c",
      "79cc07f6172c49adbf0e549e49e73e75",
      "bc2534d12eb64cc0b71609fb4d2413a5",
      "ce8ce03fa7d44868ab31cb4ab29e9828",
      "10b5ddf8e926467d9683802b01685b0f",
      "4e2261709e7d43ac9fe66ff3b3658ff1",
      "c8ec8af7670c4cc99b1679e71662df89",
      "9c91ed5b7e1f41ad8dbca219c8e651b7",
      "1809ba0e4a5b48aab7a98b373a85146f",
      "a6250c47670043bd9bf837ff10140fe0",
      "0d2d1b4396994c268404d676699e0667",
      "d3419d577f05485eb4141d5ececefe22",
      "7068d672f250498582fd170b03ee2e98",
      "3502694a28fc4493b104db35a89e8750",
      "238631d0fe2d47cc9f8b4d16ea6dda4a",
      "f1677e3f6dd443868785b225dc96a638",
      "babd61e2c561448ba4f5f11c22a650a5",
      "a02c8f5f7ca14f6c908740269b835144",
      "8d7f2bec122c4c38bb3874c259b8659b",
      "71cf16b7f8984d3eac807519c784c112",
      "281a697310fd4c22b0d1f72f3692e496",
      "7ebcce15607b4718ac943e5f130745e1",
      "af866c2a0e1b4af39791b007ea301ae9",
      "d06435c495d84eed8efda3538c766b57",
      "5d95193c335e4b48934c9dc5af367a83",
      "0421e035fdf54a838bc1e687d62f51af",
      "b91d9eb8f5e346bdac68625bf76167b3",
      "8dd43f41be86457eaa86b9ffc98cd552",
      "7bb627baefb24e00a7627609fcba4eda",
      "008d7838b8ab439dab779be89d70463e",
      "b41f38959e8c4f76bb5786f5560530c1",
      "7b7096a479e54997bc16cb55541944d9",
      "c17787a134374196b80e60f31d7fbb36",
      "af849a07d27042fe891548bf603ad207",
      "d1cba3d2bdef4f25ae3a65c8e1e15ab1",
      "6083d542e8f045b2a2ff1d296c5d7fb2",
      "917f7b27a9b04d03bfdf4ead785ca93f",
      "fa550501df9c4c41b05305939bbc1617",
      "e9b509c75b0345e8843c987bf1c598df",
      "8ce4a80626ea48a1a4ba1ca0ad190043",
      "91ad3964f61b4ac4b68b704c6fcbfa30",
      "4a821fe4b8fd4a58b12102a2ee1ea2b3",
      "61cfe657fb6c4bf995001d11f0961973",
      "d9dce245c8c4414a97d46a1ebb41740a",
      "4c03dd492869466186195312914ec7ec",
      "2fe464f7766c4bef846e262bc59b87fc",
      "a7e193115cc04a24b7d588e137efb09b",
      "81053b84b6d0415bbebe3dad5b028007",
      "b5f2765d04774985a05d609632d65ed1",
      "fd72a4af537b4352b57574dc0964c4f8",
      "3ad73a7bcdd748fea423e4f626bca467",
      "89043efb408849c598d895d23dd6479c",
      "7d96cef212dd468fbdc885598da28bfd",
      "2bcdfd5c75bc4cbc9c00aebbeab2061a",
      "44e3cfae38394aa5bc8812db4aed0233",
      "d3df783eeb604185b0ae345347bd5672",
      "49cdbcdd44344b489f2e18c2699e5673",
      "2e7af5377bed4638a939a415e93f7f76",
      "24f07da528084e70906ec732d6fa1c32",
      "7922643c58314aaaba1ec582702b6e77",
      "fe172fe16f414fbea68fcbb046a4c999",
      "92210730d9584c3283a5721f438d8ea2",
      "e26c5f91d28b4b92ab2ec62c198841d3",
      "0e745e1da18045f7b324163fcfbb5f31",
      "b02d85883946454f8ce4a28c622ad67f",
      "cc2cf40a60194d50bfdc6b8a057b8366",
      "621cb2db2cac42a09ce8b64c4760786b",
      "d6546eb14d7d4871bb5f4d3bb9467ac2",
      "2606acb222c044788bb4e5959c288916",
      "217bb816cbc94f7c9cb26e59e5dc8bb0",
      "aa912fb4cd7a4204bb31df92782896d1",
      "c4ac7a42d0a44f03a682dc229d49c521",
      "eaf2920343ec446b91c0a811b8a360ef",
      "a160af8bf0aa4f1288797aa594ba0495",
      "d0fd80150d4c4794b691fa46cf03688c",
      "12a092446b294499b1286b3b82e5de73"
     ]
    },
    "id": "aoKxi5VwhBjx",
    "outputId": "36fb2b46-3997-427f-8f9a-f171de946eb5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12a092446b294499b1286b3b82e5de73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20196/4115835899.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  lora_state_dict = torch.load(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA weights loaded from Lab2/fine_tuned_models/unet_epoch_7.pth\n"
     ]
    }
   ],
   "source": [
    "from diffusers import StableDiffusionPipeline\n",
    "from peft import PeftModel\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
    "\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.float32,\n",
    ").to(device)\n",
    "\n",
    "model_path = FINETUNED_MODEL_DIR + \"unet_epoch_7.pth\"  # Change this to your actual path\n",
    "\n",
    "unet = apply_lora_to_model(pipe.unet).to(device, torch.float32)\n",
    "load_lora_weights(unet, model_path)\n",
    "#load_lora_weights(unet, FINETUNED_MODEL_DIR + \"pytorch_lora_weights.pth\")\n",
    "pipe.unet = unet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create sample prompts for image generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hzJU9OANfcEI"
   },
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    # Common / Relatable\n",
    "    \"A baby crawling on a soft carpet with toys around\",\n",
    "    \"A person in a cozy sweater sipping coffee while reading a book by the window on a rainy afternoon\",\n",
    "    \"A child in yellow rain boots joyfully splashing in a puddle on a wet sidewalk with reflections of city lights\",\n",
    "    \"A woman in a vintage dress looking into an ornate mirror while adjusting her wide-brim hat in a softly lit room\",\n",
    "    \"A man in a blue hoodie tying his sneakers on a wooden park bench with golden morning sunlight filtering through trees\",\n",
    "    \"A girl wearing a colorful backpack waiting at a busy crosswalk as cars blur past in the city rain\",\n",
    "    \"A toddler in a sunhat giggling while reaching for shimmering bubbles floating through the sunny backyard air\",\n",
    "\n",
    "    # Fashion-Themed\n",
    "    \"A woman in a flowing red dress walking through a blooming spring garden\",\n",
    "    \"A man in a long charcoal coat and scarf walking alone down a foggy cobblestone city street at dusk\",\n",
    "    \"A fashion show runway lit by bright spotlights as models in vibrant designer gowns stride past a cheering crowd\",\n",
    "\n",
    "    # Landscape-Themed\n",
    "    \"A winding forest trail carpeted with red and orange autumn leaves glowing in soft golden evening light\",\n",
    "    \"A mirror-clear mountain lake reflecting snow-covered peaks and dense pine forests under a blue sky\",\n",
    "    \"A lavender field in full bloom under a vivid orange sunset with soft clouds glowing above\",\n",
    "\n",
    "    # Art-Themed\n",
    "    \"An artist painting bright yellow sunflowers on a large canvas in a sun-drenched studio\",\n",
    "    \"A classic oil painting of sunflowers resting on an easel beside a crystal vase of fresh tulips in a sunlit room\",\n",
    "    \"A ballerina in a white tutu stretching gracefully at a wooden barre under warm golden lighting in a quiet studio\",\n",
    "\n",
    "    # Scene-Based\n",
    "    \"A teddy bear wearing a red scarf sitting on a bookshelf\",\n",
    "    \"A white puppy sitting in a red toy wagon in a sunny park\",\n",
    "    \"A yellow toy truck on a sandy playground surface\",\n",
    "\n",
    "    # Relationship-Themed\n",
    "    \"A couple holding hands while walking under golden autumn trees with leaves falling around them\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B3VlJ4lTfcEI"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate images for the sample prompts using the fine-tuned Stable Diffusion model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221,
     "referenced_widgets": [
      "76e5d32158ea409cbb0e90c55d24777d",
      "a2d58caa5ad34521bcbb5502dedb1847",
      "4c5680b928134e4d8ef4147ad65815aa",
      "5c802e92e3f54c6c99a7f7dc06753c78",
      "607cc69236464779a1390d92c96b65be",
      "8e1dbd0f1cbd494eb891d90b93f73073",
      "69fe6ca3bb3f4466bf879339368fcceb",
      "b43394fc1dce4bb5a6abc8ad80cfec1d",
      "f22638dc98b543b59b8f6b370b8a1c07",
      "a37a8dcb6aa941f882721f6808412ef7",
      "69ff966300cf4842b8da73177d4abb3f",
      "1cd479419e044f9f8e940d3eddbd4b35",
      "dbfb4c732efe470a99df89b59fb36d64",
      "c17623442e9b4fa9927e3f38163fefc0",
      "107b4575ba91410bbad2cae83e91c23b",
      "e7c71e81d08344c680f72f0c4d8a3336",
      "6d8ea8fd76f443bd89703c6af5840d53",
      "363ae630609e4c719d98d7f7f9dc736c",
      "ecf4b8095c6141a69ac663e7097a4c78",
      "3220239156c04c60ba5c7bdca5837238",
      "582bed6c15324c0ea298a36fc106e180",
      "3a71e9beb0854fe39a05ab60f201efce",
      "a4553571a7bb40968578de733c094c2a",
      "7add87a9ce4844f5842317f131cbae2e",
      "7d89bd4c46c9426b9486b9ca3b170d23"
     ]
    },
    "id": "KXNQE9lzjslW",
    "outputId": "74709c64-9ecd-483c-bf98-c3a8bf079f88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Generating images for prompt 1/20: \"A baby crawling on a soft carpet with toys around\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e1dbd0f1cbd494eb891d90b93f73073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVED] Image 1/10 for prompt 1 saved to: Lab2/results/generated_0_0.png\n",
      "[SAVED] Image 2/10 for prompt 1 saved to: Lab2/results/generated_0_1.png\n",
      "[SAVED] Image 3/10 for prompt 1 saved to: Lab2/results/generated_0_2.png\n",
      "[SAVED] Image 4/10 for prompt 1 saved to: Lab2/results/generated_0_3.png\n",
      "[SAVED] Image 5/10 for prompt 1 saved to: Lab2/results/generated_0_4.png\n",
      "[SAVED] Image 6/10 for prompt 1 saved to: Lab2/results/generated_0_5.png\n",
      "[SAVED] Image 7/10 for prompt 1 saved to: Lab2/results/generated_0_6.png\n",
      "[SAVED] Image 8/10 for prompt 1 saved to: Lab2/results/generated_0_7.png\n",
      "[SAVED] Image 9/10 for prompt 1 saved to: Lab2/results/generated_0_8.png\n",
      "[SAVED] Image 10/10 for prompt 1 saved to: Lab2/results/generated_0_9.png\n",
      "[SAVED] Image 11/10 for prompt 1 saved to: Lab2/results/generated_0_10.png\n",
      "[SAVED] Image 12/10 for prompt 1 saved to: Lab2/results/generated_0_11.png\n",
      "[SAVED] Image 13/10 for prompt 1 saved to: Lab2/results/generated_0_12.png\n",
      "[SAVED] Image 14/10 for prompt 1 saved to: Lab2/results/generated_0_13.png\n",
      "[SAVED] Image 15/10 for prompt 1 saved to: Lab2/results/generated_0_14.png\n",
      "\n",
      "[INFO] Generating images for prompt 2/20: \"A person in a cozy sweater sipping coffee while reading a book by the window on a rainy afternoon\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69fe6ca3bb3f4466bf879339368fcceb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVED] Image 1/10 for prompt 2 saved to: Lab2/results/generated_1_0.png\n",
      "[SAVED] Image 2/10 for prompt 2 saved to: Lab2/results/generated_1_1.png\n",
      "[SAVED] Image 3/10 for prompt 2 saved to: Lab2/results/generated_1_2.png\n",
      "[SAVED] Image 4/10 for prompt 2 saved to: Lab2/results/generated_1_3.png\n",
      "[SAVED] Image 5/10 for prompt 2 saved to: Lab2/results/generated_1_4.png\n",
      "[SAVED] Image 6/10 for prompt 2 saved to: Lab2/results/generated_1_5.png\n",
      "[SAVED] Image 7/10 for prompt 2 saved to: Lab2/results/generated_1_6.png\n",
      "[SAVED] Image 8/10 for prompt 2 saved to: Lab2/results/generated_1_7.png\n",
      "[SAVED] Image 9/10 for prompt 2 saved to: Lab2/results/generated_1_8.png\n",
      "[SAVED] Image 10/10 for prompt 2 saved to: Lab2/results/generated_1_9.png\n",
      "[SAVED] Image 11/10 for prompt 2 saved to: Lab2/results/generated_1_10.png\n",
      "[SAVED] Image 12/10 for prompt 2 saved to: Lab2/results/generated_1_11.png\n",
      "[SAVED] Image 13/10 for prompt 2 saved to: Lab2/results/generated_1_12.png\n",
      "[SAVED] Image 14/10 for prompt 2 saved to: Lab2/results/generated_1_13.png\n",
      "[SAVED] Image 15/10 for prompt 2 saved to: Lab2/results/generated_1_14.png\n",
      "\n",
      "[INFO] Generating images for prompt 3/20: \"A child in yellow rain boots joyfully splashing in a puddle on a wet sidewalk with reflections of city lights\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b43394fc1dce4bb5a6abc8ad80cfec1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVED] Image 1/10 for prompt 3 saved to: Lab2/results/generated_2_0.png\n",
      "[SAVED] Image 2/10 for prompt 3 saved to: Lab2/results/generated_2_1.png\n",
      "[SAVED] Image 3/10 for prompt 3 saved to: Lab2/results/generated_2_2.png\n",
      "[SAVED] Image 4/10 for prompt 3 saved to: Lab2/results/generated_2_3.png\n",
      "[SAVED] Image 5/10 for prompt 3 saved to: Lab2/results/generated_2_4.png\n",
      "[SAVED] Image 6/10 for prompt 3 saved to: Lab2/results/generated_2_5.png\n",
      "[SAVED] Image 7/10 for prompt 3 saved to: Lab2/results/generated_2_6.png\n",
      "[SAVED] Image 8/10 for prompt 3 saved to: Lab2/results/generated_2_7.png\n",
      "[SAVED] Image 9/10 for prompt 3 saved to: Lab2/results/generated_2_8.png\n",
      "[SAVED] Image 10/10 for prompt 3 saved to: Lab2/results/generated_2_9.png\n",
      "[SAVED] Image 11/10 for prompt 3 saved to: Lab2/results/generated_2_10.png\n",
      "[SAVED] Image 12/10 for prompt 3 saved to: Lab2/results/generated_2_11.png\n",
      "[SAVED] Image 13/10 for prompt 3 saved to: Lab2/results/generated_2_12.png\n",
      "[SAVED] Image 14/10 for prompt 3 saved to: Lab2/results/generated_2_13.png\n",
      "[SAVED] Image 15/10 for prompt 3 saved to: Lab2/results/generated_2_14.png\n",
      "\n",
      "[INFO] Generating images for prompt 4/20: \"A woman in a vintage dress looking into an ornate mirror while adjusting her wide-brim hat in a softly lit room\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f22638dc98b543b59b8f6b370b8a1c07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVED] Image 1/10 for prompt 4 saved to: Lab2/results/generated_3_0.png\n",
      "[SAVED] Image 2/10 for prompt 4 saved to: Lab2/results/generated_3_1.png\n",
      "[SAVED] Image 3/10 for prompt 4 saved to: Lab2/results/generated_3_2.png\n",
      "[SAVED] Image 4/10 for prompt 4 saved to: Lab2/results/generated_3_3.png\n",
      "[SAVED] Image 5/10 for prompt 4 saved to: Lab2/results/generated_3_4.png\n",
      "[SAVED] Image 6/10 for prompt 4 saved to: Lab2/results/generated_3_5.png\n",
      "[SAVED] Image 7/10 for prompt 4 saved to: Lab2/results/generated_3_6.png\n",
      "[SAVED] Image 8/10 for prompt 4 saved to: Lab2/results/generated_3_7.png\n",
      "[SAVED] Image 9/10 for prompt 4 saved to: Lab2/results/generated_3_8.png\n",
      "[SAVED] Image 10/10 for prompt 4 saved to: Lab2/results/generated_3_9.png\n",
      "[SAVED] Image 11/10 for prompt 4 saved to: Lab2/results/generated_3_10.png\n",
      "[SAVED] Image 12/10 for prompt 4 saved to: Lab2/results/generated_3_11.png\n",
      "[SAVED] Image 13/10 for prompt 4 saved to: Lab2/results/generated_3_12.png\n",
      "[SAVED] Image 14/10 for prompt 4 saved to: Lab2/results/generated_3_13.png\n",
      "[SAVED] Image 15/10 for prompt 4 saved to: Lab2/results/generated_3_14.png\n",
      "\n",
      "[INFO] Generating images for prompt 5/20: \"A man in a blue hoodie tying his sneakers on a wooden park bench with golden morning sunlight filtering through trees\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a37a8dcb6aa941f882721f6808412ef7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVED] Image 1/10 for prompt 5 saved to: Lab2/results/generated_4_0.png\n",
      "[SAVED] Image 2/10 for prompt 5 saved to: Lab2/results/generated_4_1.png\n",
      "[SAVED] Image 3/10 for prompt 5 saved to: Lab2/results/generated_4_2.png\n",
      "[SAVED] Image 4/10 for prompt 5 saved to: Lab2/results/generated_4_3.png\n",
      "[SAVED] Image 5/10 for prompt 5 saved to: Lab2/results/generated_4_4.png\n",
      "[SAVED] Image 6/10 for prompt 5 saved to: Lab2/results/generated_4_5.png\n",
      "[SAVED] Image 7/10 for prompt 5 saved to: Lab2/results/generated_4_6.png\n",
      "[SAVED] Image 8/10 for prompt 5 saved to: Lab2/results/generated_4_7.png\n",
      "[SAVED] Image 9/10 for prompt 5 saved to: Lab2/results/generated_4_8.png\n",
      "[SAVED] Image 10/10 for prompt 5 saved to: Lab2/results/generated_4_9.png\n",
      "[SAVED] Image 11/10 for prompt 5 saved to: Lab2/results/generated_4_10.png\n",
      "[SAVED] Image 12/10 for prompt 5 saved to: Lab2/results/generated_4_11.png\n",
      "[SAVED] Image 13/10 for prompt 5 saved to: Lab2/results/generated_4_12.png\n",
      "[SAVED] Image 14/10 for prompt 5 saved to: Lab2/results/generated_4_13.png\n",
      "[SAVED] Image 15/10 for prompt 5 saved to: Lab2/results/generated_4_14.png\n",
      "\n",
      "[INFO] Generating images for prompt 6/20: \"A girl wearing a colorful backpack waiting at a busy crosswalk as cars blur past in the city rain\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69ff966300cf4842b8da73177d4abb3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVED] Image 1/10 for prompt 6 saved to: Lab2/results/generated_5_0.png\n",
      "[SAVED] Image 2/10 for prompt 6 saved to: Lab2/results/generated_5_1.png\n",
      "[SAVED] Image 3/10 for prompt 6 saved to: Lab2/results/generated_5_2.png\n",
      "[SAVED] Image 4/10 for prompt 6 saved to: Lab2/results/generated_5_3.png\n",
      "[SAVED] Image 5/10 for prompt 6 saved to: Lab2/results/generated_5_4.png\n",
      "[SAVED] Image 6/10 for prompt 6 saved to: Lab2/results/generated_5_5.png\n",
      "[SAVED] Image 7/10 for prompt 6 saved to: Lab2/results/generated_5_6.png\n",
      "[SAVED] Image 8/10 for prompt 6 saved to: Lab2/results/generated_5_7.png\n",
      "[SAVED] Image 9/10 for prompt 6 saved to: Lab2/results/generated_5_8.png\n",
      "[SAVED] Image 10/10 for prompt 6 saved to: Lab2/results/generated_5_9.png\n",
      "[SAVED] Image 11/10 for prompt 6 saved to: Lab2/results/generated_5_10.png\n",
      "[SAVED] Image 12/10 for prompt 6 saved to: Lab2/results/generated_5_11.png\n",
      "[SAVED] Image 13/10 for prompt 6 saved to: Lab2/results/generated_5_12.png\n",
      "[SAVED] Image 14/10 for prompt 6 saved to: Lab2/results/generated_5_13.png\n",
      "[SAVED] Image 15/10 for prompt 6 saved to: Lab2/results/generated_5_14.png\n",
      "\n",
      "[INFO] Generating images for prompt 7/20: \"A toddler in a sunhat giggling while reaching for shimmering bubbles floating through the sunny backyard air\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cd479419e044f9f8e940d3eddbd4b35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVED] Image 1/10 for prompt 7 saved to: Lab2/results/generated_6_0.png\n",
      "[SAVED] Image 2/10 for prompt 7 saved to: Lab2/results/generated_6_1.png\n",
      "[SAVED] Image 3/10 for prompt 7 saved to: Lab2/results/generated_6_2.png\n",
      "[SAVED] Image 4/10 for prompt 7 saved to: Lab2/results/generated_6_3.png\n",
      "[SAVED] Image 5/10 for prompt 7 saved to: Lab2/results/generated_6_4.png\n",
      "[SAVED] Image 6/10 for prompt 7 saved to: Lab2/results/generated_6_5.png\n",
      "[SAVED] Image 7/10 for prompt 7 saved to: Lab2/results/generated_6_6.png\n",
      "[SAVED] Image 8/10 for prompt 7 saved to: Lab2/results/generated_6_7.png\n",
      "[SAVED] Image 9/10 for prompt 7 saved to: Lab2/results/generated_6_8.png\n",
      "[SAVED] Image 10/10 for prompt 7 saved to: Lab2/results/generated_6_9.png\n",
      "[SAVED] Image 11/10 for prompt 7 saved to: Lab2/results/generated_6_10.png\n",
      "[SAVED] Image 12/10 for prompt 7 saved to: Lab2/results/generated_6_11.png\n",
      "[SAVED] Image 13/10 for prompt 7 saved to: Lab2/results/generated_6_12.png\n",
      "[SAVED] Image 14/10 for prompt 7 saved to: Lab2/results/generated_6_13.png\n",
      "[SAVED] Image 15/10 for prompt 7 saved to: Lab2/results/generated_6_14.png\n",
      "\n",
      "[INFO] Generating images for prompt 8/20: \"A woman in a flowing red dress walking through a blooming spring garden\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbfb4c732efe470a99df89b59fb36d64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVED] Image 1/10 for prompt 8 saved to: Lab2/results/generated_7_0.png\n",
      "[SAVED] Image 2/10 for prompt 8 saved to: Lab2/results/generated_7_1.png\n",
      "[SAVED] Image 3/10 for prompt 8 saved to: Lab2/results/generated_7_2.png\n",
      "[SAVED] Image 4/10 for prompt 8 saved to: Lab2/results/generated_7_3.png\n",
      "[SAVED] Image 5/10 for prompt 8 saved to: Lab2/results/generated_7_4.png\n",
      "[SAVED] Image 6/10 for prompt 8 saved to: Lab2/results/generated_7_5.png\n",
      "[SAVED] Image 7/10 for prompt 8 saved to: Lab2/results/generated_7_6.png\n",
      "[SAVED] Image 8/10 for prompt 8 saved to: Lab2/results/generated_7_7.png\n",
      "[SAVED] Image 9/10 for prompt 8 saved to: Lab2/results/generated_7_8.png\n",
      "[SAVED] Image 10/10 for prompt 8 saved to: Lab2/results/generated_7_9.png\n",
      "[SAVED] Image 11/10 for prompt 8 saved to: Lab2/results/generated_7_10.png\n",
      "[SAVED] Image 12/10 for prompt 8 saved to: Lab2/results/generated_7_11.png\n",
      "[SAVED] Image 13/10 for prompt 8 saved to: Lab2/results/generated_7_12.png\n",
      "[SAVED] Image 14/10 for prompt 8 saved to: Lab2/results/generated_7_13.png\n",
      "[SAVED] Image 15/10 for prompt 8 saved to: Lab2/results/generated_7_14.png\n",
      "\n",
      "[INFO] Generating images for prompt 9/20: \"A man in a long charcoal coat and scarf walking alone down a foggy cobblestone city street at dusk\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c17623442e9b4fa9927e3f38163fefc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVED] Image 1/10 for prompt 9 saved to: Lab2/results/generated_8_0.png\n",
      "[SAVED] Image 2/10 for prompt 9 saved to: Lab2/results/generated_8_1.png\n",
      "[SAVED] Image 3/10 for prompt 9 saved to: Lab2/results/generated_8_2.png\n",
      "[SAVED] Image 4/10 for prompt 9 saved to: Lab2/results/generated_8_3.png\n",
      "[SAVED] Image 5/10 for prompt 9 saved to: Lab2/results/generated_8_4.png\n",
      "[SAVED] Image 6/10 for prompt 9 saved to: Lab2/results/generated_8_5.png\n",
      "[SAVED] Image 7/10 for prompt 9 saved to: Lab2/results/generated_8_6.png\n",
      "[SAVED] Image 8/10 for prompt 9 saved to: Lab2/results/generated_8_7.png\n",
      "[SAVED] Image 9/10 for prompt 9 saved to: Lab2/results/generated_8_8.png\n",
      "[SAVED] Image 10/10 for prompt 9 saved to: Lab2/results/generated_8_9.png\n",
      "[SAVED] Image 11/10 for prompt 9 saved to: Lab2/results/generated_8_10.png\n",
      "[SAVED] Image 12/10 for prompt 9 saved to: Lab2/results/generated_8_11.png\n",
      "[SAVED] Image 13/10 for prompt 9 saved to: Lab2/results/generated_8_12.png\n",
      "[SAVED] Image 14/10 for prompt 9 saved to: Lab2/results/generated_8_13.png\n",
      "[SAVED] Image 15/10 for prompt 9 saved to: Lab2/results/generated_8_14.png\n",
      "\n",
      "[INFO] Generating images for prompt 10/20: \"A fashion show runway lit by bright spotlights as models in vibrant designer gowns stride past a cheering crowd\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "107b4575ba91410bbad2cae83e91c23b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVED] Image 1/10 for prompt 10 saved to: Lab2/results/generated_9_0.png\n",
      "[SAVED] Image 2/10 for prompt 10 saved to: Lab2/results/generated_9_1.png\n",
      "[SAVED] Image 3/10 for prompt 10 saved to: Lab2/results/generated_9_2.png\n",
      "[SAVED] Image 4/10 for prompt 10 saved to: Lab2/results/generated_9_3.png\n",
      "[SAVED] Image 5/10 for prompt 10 saved to: Lab2/results/generated_9_4.png\n",
      "[SAVED] Image 6/10 for prompt 10 saved to: Lab2/results/generated_9_5.png\n",
      "[SAVED] Image 7/10 for prompt 10 saved to: Lab2/results/generated_9_6.png\n",
      "[SAVED] Image 8/10 for prompt 10 saved to: Lab2/results/generated_9_7.png\n",
      "[SAVED] Image 9/10 for prompt 10 saved to: Lab2/results/generated_9_8.png\n",
      "[SAVED] Image 10/10 for prompt 10 saved to: Lab2/results/generated_9_9.png\n",
      "[SAVED] Image 11/10 for prompt 10 saved to: Lab2/results/generated_9_10.png\n",
      "[SAVED] Image 12/10 for prompt 10 saved to: Lab2/results/generated_9_11.png\n",
      "[SAVED] Image 13/10 for prompt 10 saved to: Lab2/results/generated_9_12.png\n",
      "[SAVED] Image 14/10 for prompt 10 saved to: Lab2/results/generated_9_13.png\n",
      "[SAVED] Image 15/10 for prompt 10 saved to: Lab2/results/generated_9_14.png\n",
      "\n",
      "[INFO] Generating images for prompt 11/20: \"A winding forest trail carpeted with red and orange autumn leaves glowing in soft golden evening light\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7c71e81d08344c680f72f0c4d8a3336",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVED] Image 1/10 for prompt 11 saved to: Lab2/results/generated_10_0.png\n",
      "[SAVED] Image 2/10 for prompt 11 saved to: Lab2/results/generated_10_1.png\n",
      "[SAVED] Image 3/10 for prompt 11 saved to: Lab2/results/generated_10_2.png\n",
      "[SAVED] Image 4/10 for prompt 11 saved to: Lab2/results/generated_10_3.png\n",
      "[SAVED] Image 5/10 for prompt 11 saved to: Lab2/results/generated_10_4.png\n",
      "[SAVED] Image 6/10 for prompt 11 saved to: Lab2/results/generated_10_5.png\n",
      "[SAVED] Image 7/10 for prompt 11 saved to: Lab2/results/generated_10_6.png\n",
      "[SAVED] Image 8/10 for prompt 11 saved to: Lab2/results/generated_10_7.png\n",
      "[SAVED] Image 9/10 for prompt 11 saved to: Lab2/results/generated_10_8.png\n",
      "[SAVED] Image 10/10 for prompt 11 saved to: Lab2/results/generated_10_9.png\n",
      "[SAVED] Image 11/10 for prompt 11 saved to: Lab2/results/generated_10_10.png\n",
      "[SAVED] Image 12/10 for prompt 11 saved to: Lab2/results/generated_10_11.png\n",
      "[SAVED] Image 13/10 for prompt 11 saved to: Lab2/results/generated_10_12.png\n",
      "[SAVED] Image 14/10 for prompt 11 saved to: Lab2/results/generated_10_13.png\n",
      "[SAVED] Image 15/10 for prompt 11 saved to: Lab2/results/generated_10_14.png\n",
      "\n",
      "[INFO] Generating images for prompt 12/20: \"A mirror-clear mountain lake reflecting snow-covered peaks and dense pine forests under a blue sky\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d8ea8fd76f443bd89703c6af5840d53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVED] Image 1/10 for prompt 12 saved to: Lab2/results/generated_11_0.png\n",
      "[SAVED] Image 2/10 for prompt 12 saved to: Lab2/results/generated_11_1.png\n",
      "[SAVED] Image 3/10 for prompt 12 saved to: Lab2/results/generated_11_2.png\n",
      "[SAVED] Image 4/10 for prompt 12 saved to: Lab2/results/generated_11_3.png\n",
      "[SAVED] Image 5/10 for prompt 12 saved to: Lab2/results/generated_11_4.png\n",
      "[SAVED] Image 6/10 for prompt 12 saved to: Lab2/results/generated_11_5.png\n",
      "[SAVED] Image 7/10 for prompt 12 saved to: Lab2/results/generated_11_6.png\n",
      "[SAVED] Image 8/10 for prompt 12 saved to: Lab2/results/generated_11_7.png\n",
      "[SAVED] Image 9/10 for prompt 12 saved to: Lab2/results/generated_11_8.png\n",
      "[SAVED] Image 10/10 for prompt 12 saved to: Lab2/results/generated_11_9.png\n",
      "[SAVED] Image 11/10 for prompt 12 saved to: Lab2/results/generated_11_10.png\n",
      "[SAVED] Image 12/10 for prompt 12 saved to: Lab2/results/generated_11_11.png\n",
      "[SAVED] Image 13/10 for prompt 12 saved to: Lab2/results/generated_11_12.png\n",
      "[SAVED] Image 14/10 for prompt 12 saved to: Lab2/results/generated_11_13.png\n",
      "[SAVED] Image 15/10 for prompt 12 saved to: Lab2/results/generated_11_14.png\n",
      "\n",
      "[INFO] Generating images for prompt 13/20: \"A lavender field in full bloom under a vivid orange sunset with soft clouds glowing above\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "363ae630609e4c719d98d7f7f9dc736c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVED] Image 1/10 for prompt 13 saved to: Lab2/results/generated_12_0.png\n",
      "[SAVED] Image 2/10 for prompt 13 saved to: Lab2/results/generated_12_1.png\n",
      "[SAVED] Image 3/10 for prompt 13 saved to: Lab2/results/generated_12_2.png\n",
      "[SAVED] Image 4/10 for prompt 13 saved to: Lab2/results/generated_12_3.png\n",
      "[SAVED] Image 5/10 for prompt 13 saved to: Lab2/results/generated_12_4.png\n",
      "[SAVED] Image 6/10 for prompt 13 saved to: Lab2/results/generated_12_5.png\n",
      "[SAVED] Image 7/10 for prompt 13 saved to: Lab2/results/generated_12_6.png\n",
      "[SAVED] Image 8/10 for prompt 13 saved to: Lab2/results/generated_12_7.png\n",
      "[SAVED] Image 9/10 for prompt 13 saved to: Lab2/results/generated_12_8.png\n",
      "[SAVED] Image 10/10 for prompt 13 saved to: Lab2/results/generated_12_9.png\n",
      "[SAVED] Image 11/10 for prompt 13 saved to: Lab2/results/generated_12_10.png\n",
      "[SAVED] Image 12/10 for prompt 13 saved to: Lab2/results/generated_12_11.png\n",
      "[SAVED] Image 13/10 for prompt 13 saved to: Lab2/results/generated_12_12.png\n",
      "[SAVED] Image 14/10 for prompt 13 saved to: Lab2/results/generated_12_13.png\n",
      "[SAVED] Image 15/10 for prompt 13 saved to: Lab2/results/generated_12_14.png\n",
      "\n",
      "[INFO] Generating images for prompt 14/20: \"An artist painting bright yellow sunflowers on a large canvas in a sun-drenched studio\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecf4b8095c6141a69ac663e7097a4c78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVED] Image 1/10 for prompt 14 saved to: Lab2/results/generated_13_0.png\n",
      "[SAVED] Image 2/10 for prompt 14 saved to: Lab2/results/generated_13_1.png\n",
      "[SAVED] Image 3/10 for prompt 14 saved to: Lab2/results/generated_13_2.png\n",
      "[SAVED] Image 4/10 for prompt 14 saved to: Lab2/results/generated_13_3.png\n",
      "[SAVED] Image 5/10 for prompt 14 saved to: Lab2/results/generated_13_4.png\n",
      "[SAVED] Image 6/10 for prompt 14 saved to: Lab2/results/generated_13_5.png\n",
      "[SAVED] Image 7/10 for prompt 14 saved to: Lab2/results/generated_13_6.png\n",
      "[SAVED] Image 8/10 for prompt 14 saved to: Lab2/results/generated_13_7.png\n",
      "[SAVED] Image 9/10 for prompt 14 saved to: Lab2/results/generated_13_8.png\n",
      "[SAVED] Image 10/10 for prompt 14 saved to: Lab2/results/generated_13_9.png\n",
      "[SAVED] Image 11/10 for prompt 14 saved to: Lab2/results/generated_13_10.png\n",
      "[SAVED] Image 12/10 for prompt 14 saved to: Lab2/results/generated_13_11.png\n",
      "[SAVED] Image 13/10 for prompt 14 saved to: Lab2/results/generated_13_12.png\n",
      "[SAVED] Image 14/10 for prompt 14 saved to: Lab2/results/generated_13_13.png\n",
      "[SAVED] Image 15/10 for prompt 14 saved to: Lab2/results/generated_13_14.png\n",
      "\n",
      "[INFO] Generating images for prompt 15/20: \"A classic oil painting of sunflowers resting on an easel beside a crystal vase of fresh tulips in a sunlit room\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3220239156c04c60ba5c7bdca5837238",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVED] Image 1/10 for prompt 15 saved to: Lab2/results/generated_14_0.png\n",
      "[SAVED] Image 2/10 for prompt 15 saved to: Lab2/results/generated_14_1.png\n",
      "[SAVED] Image 3/10 for prompt 15 saved to: Lab2/results/generated_14_2.png\n",
      "[SAVED] Image 4/10 for prompt 15 saved to: Lab2/results/generated_14_3.png\n",
      "[SAVED] Image 5/10 for prompt 15 saved to: Lab2/results/generated_14_4.png\n",
      "[SAVED] Image 6/10 for prompt 15 saved to: Lab2/results/generated_14_5.png\n",
      "[SAVED] Image 7/10 for prompt 15 saved to: Lab2/results/generated_14_6.png\n",
      "[SAVED] Image 8/10 for prompt 15 saved to: Lab2/results/generated_14_7.png\n",
      "[SAVED] Image 9/10 for prompt 15 saved to: Lab2/results/generated_14_8.png\n",
      "[SAVED] Image 10/10 for prompt 15 saved to: Lab2/results/generated_14_9.png\n",
      "[SAVED] Image 11/10 for prompt 15 saved to: Lab2/results/generated_14_10.png\n",
      "[SAVED] Image 12/10 for prompt 15 saved to: Lab2/results/generated_14_11.png\n",
      "[SAVED] Image 13/10 for prompt 15 saved to: Lab2/results/generated_14_12.png\n",
      "[SAVED] Image 14/10 for prompt 15 saved to: Lab2/results/generated_14_13.png\n",
      "[SAVED] Image 15/10 for prompt 15 saved to: Lab2/results/generated_14_14.png\n",
      "\n",
      "[INFO] Generating images for prompt 16/20: \"A ballerina in a white tutu stretching gracefully at a wooden barre under warm golden lighting in a quiet studio\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "582bed6c15324c0ea298a36fc106e180",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVED] Image 1/10 for prompt 16 saved to: Lab2/results/generated_15_0.png\n",
      "[SAVED] Image 2/10 for prompt 16 saved to: Lab2/results/generated_15_1.png\n",
      "[SAVED] Image 3/10 for prompt 16 saved to: Lab2/results/generated_15_2.png\n",
      "[SAVED] Image 4/10 for prompt 16 saved to: Lab2/results/generated_15_3.png\n",
      "[SAVED] Image 5/10 for prompt 16 saved to: Lab2/results/generated_15_4.png\n",
      "[SAVED] Image 6/10 for prompt 16 saved to: Lab2/results/generated_15_5.png\n",
      "[SAVED] Image 7/10 for prompt 16 saved to: Lab2/results/generated_15_6.png\n",
      "[SAVED] Image 8/10 for prompt 16 saved to: Lab2/results/generated_15_7.png\n",
      "[SAVED] Image 9/10 for prompt 16 saved to: Lab2/results/generated_15_8.png\n",
      "[SAVED] Image 10/10 for prompt 16 saved to: Lab2/results/generated_15_9.png\n",
      "[SAVED] Image 11/10 for prompt 16 saved to: Lab2/results/generated_15_10.png\n",
      "[SAVED] Image 12/10 for prompt 16 saved to: Lab2/results/generated_15_11.png\n",
      "[SAVED] Image 13/10 for prompt 16 saved to: Lab2/results/generated_15_12.png\n",
      "[SAVED] Image 14/10 for prompt 16 saved to: Lab2/results/generated_15_13.png\n",
      "[SAVED] Image 15/10 for prompt 16 saved to: Lab2/results/generated_15_14.png\n",
      "\n",
      "[INFO] Generating images for prompt 17/20: \"A teddy bear wearing a red scarf sitting on a bookshelf\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a71e9beb0854fe39a05ab60f201efce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVED] Image 1/10 for prompt 17 saved to: Lab2/results/generated_16_0.png\n",
      "[SAVED] Image 2/10 for prompt 17 saved to: Lab2/results/generated_16_1.png\n",
      "[SAVED] Image 3/10 for prompt 17 saved to: Lab2/results/generated_16_2.png\n",
      "[SAVED] Image 4/10 for prompt 17 saved to: Lab2/results/generated_16_3.png\n",
      "[SAVED] Image 5/10 for prompt 17 saved to: Lab2/results/generated_16_4.png\n",
      "[SAVED] Image 6/10 for prompt 17 saved to: Lab2/results/generated_16_5.png\n",
      "[SAVED] Image 7/10 for prompt 17 saved to: Lab2/results/generated_16_6.png\n",
      "[SAVED] Image 8/10 for prompt 17 saved to: Lab2/results/generated_16_7.png\n",
      "[SAVED] Image 9/10 for prompt 17 saved to: Lab2/results/generated_16_8.png\n",
      "[SAVED] Image 10/10 for prompt 17 saved to: Lab2/results/generated_16_9.png\n",
      "[SAVED] Image 11/10 for prompt 17 saved to: Lab2/results/generated_16_10.png\n",
      "[SAVED] Image 12/10 for prompt 17 saved to: Lab2/results/generated_16_11.png\n",
      "[SAVED] Image 13/10 for prompt 17 saved to: Lab2/results/generated_16_12.png\n",
      "[SAVED] Image 14/10 for prompt 17 saved to: Lab2/results/generated_16_13.png\n",
      "[SAVED] Image 15/10 for prompt 17 saved to: Lab2/results/generated_16_14.png\n",
      "\n",
      "[INFO] Generating images for prompt 18/20: \"A white puppy sitting in a red toy wagon in a sunny park\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4553571a7bb40968578de733c094c2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVED] Image 1/10 for prompt 18 saved to: Lab2/results/generated_17_0.png\n",
      "[SAVED] Image 2/10 for prompt 18 saved to: Lab2/results/generated_17_1.png\n",
      "[SAVED] Image 3/10 for prompt 18 saved to: Lab2/results/generated_17_2.png\n",
      "[SAVED] Image 4/10 for prompt 18 saved to: Lab2/results/generated_17_3.png\n",
      "[SAVED] Image 5/10 for prompt 18 saved to: Lab2/results/generated_17_4.png\n",
      "[SAVED] Image 6/10 for prompt 18 saved to: Lab2/results/generated_17_5.png\n",
      "[SAVED] Image 7/10 for prompt 18 saved to: Lab2/results/generated_17_6.png\n",
      "[SAVED] Image 8/10 for prompt 18 saved to: Lab2/results/generated_17_7.png\n",
      "[SAVED] Image 9/10 for prompt 18 saved to: Lab2/results/generated_17_8.png\n",
      "[SAVED] Image 10/10 for prompt 18 saved to: Lab2/results/generated_17_9.png\n",
      "[SAVED] Image 11/10 for prompt 18 saved to: Lab2/results/generated_17_10.png\n",
      "[SAVED] Image 12/10 for prompt 18 saved to: Lab2/results/generated_17_11.png\n",
      "[SAVED] Image 13/10 for prompt 18 saved to: Lab2/results/generated_17_12.png\n",
      "[SAVED] Image 14/10 for prompt 18 saved to: Lab2/results/generated_17_13.png\n",
      "[SAVED] Image 15/10 for prompt 18 saved to: Lab2/results/generated_17_14.png\n",
      "\n",
      "[INFO] Generating images for prompt 19/20: \"A yellow toy truck on a sandy playground surface\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7add87a9ce4844f5842317f131cbae2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVED] Image 1/10 for prompt 19 saved to: Lab2/results/generated_18_0.png\n",
      "[SAVED] Image 2/10 for prompt 19 saved to: Lab2/results/generated_18_1.png\n",
      "[SAVED] Image 3/10 for prompt 19 saved to: Lab2/results/generated_18_2.png\n",
      "[SAVED] Image 4/10 for prompt 19 saved to: Lab2/results/generated_18_3.png\n",
      "[SAVED] Image 5/10 for prompt 19 saved to: Lab2/results/generated_18_4.png\n",
      "[SAVED] Image 6/10 for prompt 19 saved to: Lab2/results/generated_18_5.png\n",
      "[SAVED] Image 7/10 for prompt 19 saved to: Lab2/results/generated_18_6.png\n",
      "[SAVED] Image 8/10 for prompt 19 saved to: Lab2/results/generated_18_7.png\n",
      "[SAVED] Image 9/10 for prompt 19 saved to: Lab2/results/generated_18_8.png\n",
      "[SAVED] Image 10/10 for prompt 19 saved to: Lab2/results/generated_18_9.png\n",
      "[SAVED] Image 11/10 for prompt 19 saved to: Lab2/results/generated_18_10.png\n",
      "[SAVED] Image 12/10 for prompt 19 saved to: Lab2/results/generated_18_11.png\n",
      "[SAVED] Image 13/10 for prompt 19 saved to: Lab2/results/generated_18_12.png\n",
      "[SAVED] Image 14/10 for prompt 19 saved to: Lab2/results/generated_18_13.png\n",
      "[SAVED] Image 15/10 for prompt 19 saved to: Lab2/results/generated_18_14.png\n",
      "\n",
      "[INFO] Generating images for prompt 20/20: \"A couple holding hands while walking under golden autumn trees with leaves falling around them\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d89bd4c46c9426b9486b9ca3b170d23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVED] Image 1/10 for prompt 20 saved to: Lab2/results/generated_19_0.png\n",
      "[SAVED] Image 2/10 for prompt 20 saved to: Lab2/results/generated_19_1.png\n",
      "[SAVED] Image 3/10 for prompt 20 saved to: Lab2/results/generated_19_2.png\n",
      "[SAVED] Image 4/10 for prompt 20 saved to: Lab2/results/generated_19_3.png\n",
      "[SAVED] Image 5/10 for prompt 20 saved to: Lab2/results/generated_19_4.png\n",
      "[SAVED] Image 6/10 for prompt 20 saved to: Lab2/results/generated_19_5.png\n",
      "[SAVED] Image 7/10 for prompt 20 saved to: Lab2/results/generated_19_6.png\n",
      "[SAVED] Image 8/10 for prompt 20 saved to: Lab2/results/generated_19_7.png\n",
      "[SAVED] Image 9/10 for prompt 20 saved to: Lab2/results/generated_19_8.png\n",
      "[SAVED] Image 10/10 for prompt 20 saved to: Lab2/results/generated_19_9.png\n",
      "[SAVED] Image 11/10 for prompt 20 saved to: Lab2/results/generated_19_10.png\n",
      "[SAVED] Image 12/10 for prompt 20 saved to: Lab2/results/generated_19_11.png\n",
      "[SAVED] Image 13/10 for prompt 20 saved to: Lab2/results/generated_19_12.png\n",
      "[SAVED] Image 14/10 for prompt 20 saved to: Lab2/results/generated_19_13.png\n",
      "[SAVED] Image 15/10 for prompt 20 saved to: Lab2/results/generated_19_14.png\n"
     ]
    }
   ],
   "source": [
    "generated_images = []\n",
    "\n",
    "for i, prompt in enumerate(prompts):\n",
    "    print(f\"\\n[INFO] Generating images for prompt {i+1}/{len(prompts)}: \\\"{prompt}\\\"\")\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    generator = torch.Generator(device).manual_seed(i * 37)\n",
    "\n",
    "    images = pipe(prompt, generator=generator, num_inference_steps=50, guidance_scale=10, num_images_per_prompt=15).images\n",
    "\n",
    "    for j, image in enumerate(images):\n",
    "        generated_images.append((prompt, image))\n",
    "        file_path = RESULTS_DIR + f\"generated_{i}_{j}.png\"\n",
    "        image.save(file_path)\n",
    "        print(f\"[SAVED] Image {j+1}/10 for prompt {i+1} saved to: {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Inception Score and CLIP Score for the generated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j8Y4ZfCdfcEJ"
   },
   "outputs": [],
   "source": [
    "from torchmetrics.image.inception import InceptionScore\n",
    "from torchvision.transforms import ToTensor\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from PIL import Image\n",
    "import os\n",
    "import torch\n",
    "import torch_fidelity\n",
    "\n",
    "def evaluate_generated_images(prompts):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Ensure the resized results directory exists\n",
    "    os.makedirs(RESIZED_RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "    # Resize all generated images to 299x299 for Inception Score\n",
    "    for filename in os.listdir(RESULTS_DIR):\n",
    "        if filename.endswith(\".png\") or filename.endswith(\".jpg\"):\n",
    "            img_path = os.path.join(RESULTS_DIR, filename)\n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "            img = img.resize((299, 299), Image.LANCZOS)\n",
    "            img.save(os.path.join(RESIZED_RESULTS_DIR, filename))\n",
    "\n",
    "    # Calculate Inception Score\n",
    "    metrics = torch_fidelity.calculate_metrics(\n",
    "        input1=RESIZED_RESULTS_DIR,\n",
    "        input2=None,\n",
    "        cuda=torch.cuda.is_available(),\n",
    "        isc=True,\n",
    "        fid=False,\n",
    "    )\n",
    "    inception_score = metrics[\"inception_score_mean\"]\n",
    "\n",
    "    # Load CLIP model\n",
    "    clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\n",
    "    clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "\n",
    "    # Track best CLIP score per prompt index\n",
    "    best_clip_scores = {i: float('-inf') for i in range(len(prompts))}\n",
    "\n",
    "    for filename in os.listdir(RESULTS_DIR):\n",
    "        if filename.endswith(\".png\") and filename.startswith(\"generated_\"):\n",
    "            parts = filename.split('_')\n",
    "            i = int(parts[1])  # Extract prompt index\n",
    "            prompt = prompts[i]\n",
    "\n",
    "            image_path = os.path.join(RESULTS_DIR, filename)\n",
    "            image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "            inputs = clip_processor(text=prompt, images=image, return_tensors=\"pt\", padding=True).to(device)\n",
    "            outputs = clip_model(**inputs)\n",
    "            similarity = outputs.logits_per_image[0][0].item()\n",
    "\n",
    "            # Update best score for this prompt\n",
    "            if similarity > best_clip_scores[i]:\n",
    "                best_clip_scores[i] = similarity\n",
    "\n",
    "    print(best_clip_scores)\n",
    "\n",
    "    # Compute average of best scores per prompt\n",
    "    avg_best_clip_score = sum(best_clip_scores.values()) / len(best_clip_scores)\n",
    "\n",
    "\n",
    "    return inception_score, avg_best_clip_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NSDAmn3efcEJ",
    "outputId": "3eca6634-9443-4d25-c697-bdfe19dc330c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating feature extractor \"inception-v3-compat\" with features ['logits_unbiased']\n",
      "Extracting features from input1\n",
      "Looking for samples non-recursivelty in \"Lab2/resized_images/\" with extensions png,jpg,jpeg\n",
      "Found 300 samples\n",
      "Processing samples                                                         \n",
      "Inception Score: 8.502929916187103 ± 0.4503573635875724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 41.29104232788086, 1: 37.033416748046875, 2: 41.071510314941406, 3: 37.256019592285156, 4: 37.072837829589844, 5: 40.56396484375, 6: 37.84281921386719, 7: 39.01365661621094, 8: 37.351470947265625, 9: 35.16120910644531, 10: 35.07152557373047, 11: 35.06605529785156, 12: 35.2185173034668, 13: 41.09211349487305, 14: 35.693172454833984, 15: 34.822296142578125, 16: 41.209022521972656, 17: 40.76188278198242, 18: 40.85335922241211, 19: 36.9642448425293}\n",
      "Inception Score: 8.50\n",
      "Avg. Best CLIP Similarity per Prompt: 38.02\n"
     ]
    }
   ],
   "source": [
    "inception_score, avg_best_clip_score = evaluate_generated_images(prompts)\n",
    "\n",
    "print(f\"Inception Score: {inception_score:.2f}\")\n",
    "print(f\"Avg. Best CLIP Similarity per Prompt: {avg_best_clip_score:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
